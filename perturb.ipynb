{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa754c1",
   "metadata": {},
   "source": [
    "# Evaluation of fidelity by feature perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915a3bd",
   "metadata": {},
   "source": [
    "This notebook performs the perturbation of input images according to the previously calculated importance estimates. The model outputs (logits) are recorded as a function of the fraction of perturbed pixels\n",
    "\n",
    "First choose for which model you want to perform the perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f36aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        0: \"cifar\",\n",
    "        1: \"food101\",\n",
    "        2: \"imgnet\"\n",
    "}\n",
    "model_name = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e38fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "134b95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import saliency.core as saliency\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from numpy import trapz\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numba import njit\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fad478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n",
      "Global seed set to 7\n",
      "Global seed set to 7\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lightning_models.model_imagenet import ImgNet_ResNet\n",
    "from lightning_models.model_cifar_resnet import CIFAR_ResNet\n",
    "from lightning_models.model_food101 import Food101_ResNet\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision.datasets import Food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b089b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be6ff9",
   "metadata": {},
   "source": [
    "### Define some defaults for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc230cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "set_matplotlib_formats('pdf', 'svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14717cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=20)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15)    # legend fontsize\n",
    "plt.rc('font', size=18)\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a052c83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Defining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5875c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform2d = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # normalizes images to [-1,1]\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform3d = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # normalizes images to [-1,1]\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_imgnet = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_food101 = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.561, 0.440, 0.312), (0.252, 0.256, 0.259)),\n",
    "        ]\n",
    ")\n",
    "\n",
    "cifar = CIFAR10('./data', train=False, transform=transform3d)\n",
    "imgnet = ImageNet(root='/home/lbrocki/AugmentData/data', \n",
    "                  split='val', \n",
    "                  transform=transform_imgnet)\n",
    "food101 = Food101(\"/home/lbrocki/AugmentData/data/\", split=\"test\", transform=transform_food101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d57d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.load('test_idx_val_imgnet.npy')\n",
    "imgnet_test = torch.utils.data.Subset(imgnet, test_indices)\n",
    "\n",
    "_, food_test_indices = train_test_split(\n",
    "    np.arange(0,len(food101)), \n",
    "    test_size=5000, random_state=42\n",
    ")\n",
    "food101_test = torch.utils.data.Subset(food101, food_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19eadf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(model_name == \"cifar\"):\n",
    "    data = cifar\n",
    "elif(model_name == \"food101\"):\n",
    "    data = food101_test\n",
    "elif(model_name == \"imgnet\"):\n",
    "    data = imgnet_test\n",
    "else:\n",
    "    print(\"model name error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25027e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Obtain perturbation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef22d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def get_grid2d(arr, descending=True):\n",
    "    grid = []\n",
    "    xs, ys = arr.shape\n",
    "    for x in range(xs):\n",
    "        for y in range(ys):\n",
    "            grid.append([arr[x,y],x,y])\n",
    "    grid = np.array(grid)\n",
    "    grid_sorted = grid[grid[:, 0].argsort()]\n",
    "    if(descending):\n",
    "        return grid_sorted[::-1]\n",
    "    else:\n",
    "        return grid_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "720c76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_n(img, attribution, n, reverse=True):\n",
    "    grid = get_grid2d(attribution, descending=reverse)\n",
    "\n",
    "    x = grid[:,1].astype(np.int64)[:n]\n",
    "    y = grid[:,2].astype(np.int64)[:n]\n",
    "    \n",
    "    img_cp = np.copy(img)\n",
    "\n",
    "    img_cp[:,x,y] = 0.0\n",
    "    \n",
    "    return img_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0267d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(model_path):\n",
    "    estimator_path = 'estimators/'+model_path+'/'\n",
    "    logits_path = 'logits/'+model_path+'/'\n",
    "    \n",
    "    if(model_name == \"cifar\"):\n",
    "        model = CIFAR_ResNet().to(device)\n",
    "    elif(model_name == \"food101\"):\n",
    "        model = Food101_ResNet().to(device)\n",
    "    elif(model_name == \"imgnet\"):\n",
    "        model = ImgNet_ResNet().to(device)\n",
    "    else:\n",
    "        print(\"model name error\")\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"weights/{model_path}\"))\n",
    "\n",
    "    try:\n",
    "        os.makedirs(logits_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    return estimator_path, logits_path, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c44a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(estimator, estim_path, logits_path, model, \n",
    "            data, ch_mode, random_label=False, xinput=False):\n",
    "    print(estim_path, logits_path)\n",
    "        \n",
    "    all_LiF = []\n",
    "    all_MiF = []\n",
    "\n",
    "    #by sorting maps_path in ascending order we make sure that the \n",
    "    #saliency maps match with the images and labels in the for loop \n",
    "    maps_path = glob.glob(estim_path+estimator+'/*')\n",
    "    maps_path.sort()\n",
    "#     for i in tqdm(range(len(data))):\n",
    "    for i in tqdm(range(10)):\n",
    "        img = data[i][0]\n",
    "        c,h,w = img.shape\n",
    "        if(estimator != 'random'):\n",
    "            map_ = np.load(maps_path[i], allow_pickle=True)\n",
    "            if(xinput):\n",
    "                map_ = np.asarray(img)*map_\n",
    "            if(ch_mode == 'abs_sum'):\n",
    "                map_ = np.abs(map_)\n",
    "        else:\n",
    "            map_ = np.random.uniform(0, 1,(h, w))\n",
    "        if(len(map_.shape) == 3):\n",
    "            if(map_.shape[0] == 3):\n",
    "                map_ = np.sum(map_, axis=0)\n",
    "            else:\n",
    "                map_ = map_.squeeze(0)\n",
    "        assert len(map_.shape) == 2\n",
    "        step = int(h*w*0.05)\n",
    "        pixel_range = np.arange(0, h*w, step)\n",
    "\n",
    "        predicted_label = model(img.unsqueeze(0).to(device)).argmax()\n",
    "        batch_LiF = torch.zeros((len(pixel_range), c, h, w), device=device)\n",
    "        batch_MiF = torch.zeros((len(pixel_range), c, h, w), device=device)\n",
    "        \n",
    "        for k, n in enumerate(pixel_range):\n",
    "            img_p_LiF = perturb_n(img, map_, n, False)\n",
    "            img_p_MiF = perturb_n(img, map_, n, True)\n",
    "\n",
    "            img_p_LiF = torch.tensor(img_p_LiF, device=device)\n",
    "            img_p_MiF = torch.tensor(img_p_MiF, device=device)\n",
    "\n",
    "            batch_LiF[k] = img_p_LiF\n",
    "            batch_MiF[k] = img_p_MiF\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            scores_LiF = model(batch_LiF)[:,predicted_label].detach().cpu().numpy()\n",
    "            scores_MiF = model(batch_MiF)[:,predicted_label].detach().cpu().numpy()\n",
    "\n",
    "        all_LiF.append(scores_LiF)\n",
    "        all_MiF.append(scores_MiF)\n",
    "\n",
    "    all_LiF = np.array(all_LiF)\n",
    "    all_MiF = np.array(all_MiF)\n",
    "    if(xinput):\n",
    "        str_xi = 'xi_'\n",
    "    else:\n",
    "        str_xi = ''\n",
    "\n",
    "    np.save(f\"{logits_path}{estimator}_{ch_mode}_{str_xi}MiF\", all_MiF)\n",
    "    np.save(f\"{logits_path}{estimator}_{ch_mode}_{str_xi}LiF\", all_LiF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a78559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar/rand.pt intgrad sum\n",
      "[Errno 17] File exists: 'logits/cifar/rand.pt/'\n",
      "estimators/cifar/rand.pt/ logits/cifar/rand.pt/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar/rect.pt intgrad sum\n",
      "[Errno 17] File exists: 'logits/cifar/rect.pt/'\n",
      "estimators/cifar/rect.pt/ logits/cifar/rect.pt/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 29.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar/none.pt intgrad sum\n",
      "[Errno 17] File exists: 'logits/cifar/none.pt/'\n",
      "estimators/cifar/none.pt/ logits/cifar/none.pt/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 30.27it/s]\n"
     ]
    }
   ],
   "source": [
    "perturb_method = [\"rand\", \"rect\", \"none\"]\n",
    "model_paths = [f\"{model_name}/{p}.pt\" for p in perturb_method]\n",
    "\n",
    "# sum: sum color channels\n",
    "# abs_sum: first abs then sum\n",
    "\n",
    "# specify for which importance estimators you want to perform perturbation\n",
    "# the last argument toggles elementwise multiplication with input image\n",
    "estim_list = [\n",
    "    ['random', 'sum', False],\n",
    "    ['intgrad', 'sum', False],\n",
    "    ['intgrad', 'abs_sum', False],\n",
    "    ['vanilla', 'sum', False],\n",
    "    ['vanilla', 'abs_sum', False],\n",
    "    ['vanilla', 'sum', True],\n",
    "    ['vanilla', 'abs_sum', True],\n",
    "    ['smooth', 'sum', False],\n",
    "    ['smooth', 'abs_sum', False],\n",
    "    ['smooth', 'sum', True],\n",
    "    ['smooth', 'abs_sum', True],\n",
    "    ['smooth_sq', 'sum', True],\n",
    "    ['smooth_sq', 'sum', False]\n",
    "]\n",
    "random_label = False\n",
    "for model_path in model_paths:\n",
    "    for param in estim_list:\n",
    "        estimator, ch_mode, xinput = param\n",
    "        print(model_path, estimator, ch_mode)\n",
    "        estim_path, logits_path, model = setup(model_path)\n",
    "        perturb(estimator, estim_path, logits_path, model, data, ch_mode, random_label, xinput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acfbfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate area between the MIF and LIF curves (fildelity metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f56d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC(logits):\n",
    "    x = np.linspace(0,100,len(logits))\n",
    "    return trapz(logits/logits[0], x)\n",
    "val_dict = {}\n",
    "\n",
    "def fill_dict(val_dict, model_names):\n",
    "    for model_path in model_names:\n",
    "        print(model_path)\n",
    "        val_dict[model_path] = {}\n",
    "        for param in estim_list:\n",
    "            str_xi = \"\"\n",
    "            if(param[2]):\n",
    "                str_xi = \"_xi\"\n",
    "            estim = f\"{param[0]}_{param[1]}{str_xi}\"\n",
    "            \n",
    "            val_dict[model_path][estim] = {}\n",
    "            logits_path = f'logits/{model_path}/'\n",
    "            \n",
    "            logits_MiF = np.load(f\"{logits_path}{estim}_MiF.npy\")\n",
    "            logits_LiF = np.load(f\"{logits_path}{estim}_LiF.npy\")\n",
    "            AUC_MiF = []\n",
    "            AUC_LiF = []\n",
    "            for i,j in zip(logits_MiF, logits_LiF):\n",
    "                AUC_MiF.append(AUC(i))\n",
    "                AUC_LiF.append(AUC(j))\n",
    "            \n",
    "            mean_MiF = np.mean(AUC_MiF)\n",
    "            mean_LiF = np.mean(AUC_LiF)\n",
    "            var_MiF = np.var(AUC_MiF)\n",
    "            var_LiF = np.var(AUC_LiF)\n",
    "                        \n",
    "            std_diff = np.sqrt(var_MiF + var_LiF)\n",
    "            \n",
    "            ci_diff = stats.norm.interval(0.95, loc=mean_LiF-mean_MiF, \n",
    "                             scale=std_diff / np.sqrt(len(AUC_MiF)))\n",
    "            \n",
    "            pm = np.abs(mean_LiF-mean_MiF-ci_diff[0])\n",
    "            \n",
    "            val_dict[model_path][estim][\"MIF\"] = mean_MiF\n",
    "            val_dict[model_path][estim][\"LIF\"] = mean_LiF\n",
    "            val_dict[model_path][estim][\"Diff\"] = mean_LiF - mean_MiF\n",
    "            val_dict[model_path][estim][\"CI\"] = pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05079680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar/rand.pt\n",
      "cifar/rect.pt\n",
      "cifar/none.pt\n"
     ]
    }
   ],
   "source": [
    "fill_dict(val_dict, model_paths)\n",
    "with open('logits/logits_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(val_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "570e0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logits/logits_dict.pkl', 'rb') as handle:\n",
    "    val_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efaae913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intgrad_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CI</th>\n",
       "      <td>13.412625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff</th>\n",
       "      <td>59.411431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiF</th>\n",
       "      <td>87.880639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiF</th>\n",
       "      <td>28.469208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      intgrad_sum\n",
       "CI      13.412625\n",
       "Diff    59.411431\n",
       "LiF     87.880639\n",
       "MiF     28.469208"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val_dict[\"cifar/rand.pt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c15368",
   "metadata": {},
   "source": [
    "MIF: area under MIF curve <br />\n",
    "LIF: area under LIF curve <br />\n",
    "Diff: area between those curves <br />\n",
    "CI: symmetrical confidence interval for diff <br />\n",
    "\n",
    "$\\text{fidelity} = \\text{Diff} \\pm \\text{CI}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7331ad",
   "metadata": {},
   "source": [
    "### Create a plot comparing the MIF and LIF curves for different pertubation schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1, figsize=(5,10))\n",
    "estim = 'intgrad_sum_MiF'\n",
    "logits_list = []\n",
    "for model_path in model_paths:\n",
    "    logits_path = f'logits/{model_path}/'\n",
    "    logits = np.load(logits_path+estim+'.npy')\n",
    "    mean_logits = np.mean(logits, axis=0)\n",
    "    logits_list.append([model_path, mean_logits/mean_logits[0]])\n",
    "for model_name, logits in logits_list:\n",
    "    if(\"rand\" in model_name):\n",
    "        label = \"Proposed\"\n",
    "    elif(\"rect\" in model_name):\n",
    "        label = \"Rectangle\"\n",
    "    else:\n",
    "        label = \"None\"\n",
    "    x = np.linspace(0, 100, logits.shape[0])\n",
    "    axes[0].xaxis.set_ticklabels([])\n",
    "    axes[0].plot(x, logits, label=label)\n",
    "    axes[0].legend()\n",
    "    axes[0].set_ylabel('MIF')\n",
    "    \n",
    "estim = 'intgrad_sum_LiF'\n",
    "logits_list = []\n",
    "for model_path in model_paths:\n",
    "    logits_path = f'logits/{model_path}/'\n",
    "    logits = np.load(logits_path+estim+'.npy')\n",
    "    mean_logits = np.mean(logits, axis=0)\n",
    "    logits_list.append([model_path, mean_logits/mean_logits[0]])\n",
    "for model_name, logits in logits_list:\n",
    "    x = np.linspace(0, 100, logits.shape[0])\n",
    "    axes[1].plot(x, logits, label=label)\n",
    "    axes[1].set_ylabel('LIF')\n",
    "    axes[1].set_xlabel('percentage of masked pixels')\n",
    "fig.text(-0.05, 0.5, 'logits', va='center', rotation='vertical')\n",
    "# plt.savefig(\"graphics/cifar_intgrad.svg\", bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
